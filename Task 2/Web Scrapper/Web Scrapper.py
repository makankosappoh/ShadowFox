# INTERMIDIATE TASK - WEB SCRAPPER
import requests
from bs4 import BeautifulSoup

req = requests.get("https://www.apple.com/in/") #in the website there was some verification bot issue so theres an alt link fo site

soup = BeautifulSoup(req.content, "html.parser")

#--------------------------------------------------SOME BASIC OPERATIONS DONE FOR WEB SCRAPPING-------------------------------------------------------------------#
#Display content of website
print(soup.prettify())

#extracting all texts information
print(soup.get_text())

#extracting titles
print(soup.title)

#extracting all the URLs found within a pageâ€™s <a> tags
for link in soup.find_all('a'):
    print(link.get('href'))
    
#extracting all headings
headings = soup.find_all(['h1', 'h2', 'h3'])

# Find all <p> tags
paragraphs = soup.find_all('p')
# Print each paragraph's text
for idx, paragraph in enumerate(paragraphs):
    print(f"Paragraph {idx + 1}: {paragraph.text}")
#-------------------------------------------------------------------------------------------------------------------------------------------------#
file_path = 'web_scrapper_extracted_data.txt'
# Save the data to a text file
with open(file_path, 'w', encoding='utf-8') as file:
    for heading in headings:
        file.write(f"{heading.name}: {heading.text.strip()}\n")
print(f"Data saved to {file_path}")
#------------------------------------------------------------------------------------------------------------------------------------------------#
